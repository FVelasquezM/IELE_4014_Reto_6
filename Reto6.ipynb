{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --user numpy\n",
    "%pip install --user matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptronClassifier:\n",
    "    \n",
    "    def __init__(self, hidden_layer, suppress_output = False):\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.suppress_output = False\n",
    "        self.hidden_layer = hidden_layer\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        #Se hará la suposición que todas las filas de X tienen el mismo número de columnas.\n",
    "        self.build_network(len(X[0]))\n",
    "        \n",
    "        self.feed_forward(X[math.floor(random.random()*len(X))])\n",
    "\n",
    "    \n",
    "    #input_length esero entero positivo mayor a 1 que representa la cantidad de atributos de cada\n",
    "    #dato de entrada (sin incluir el que se busca predecir).\n",
    "    #hidden_dimensions es una lista que contiene las dimensiones de las capas escondidas de la red\n",
    "    #si hidden_dimensions es [3,3,3] se crearán tres capas escondidas de \n",
    "    def build_network(self, input_length):\n",
    "        \n",
    "        dimensions = self.hidden_layer                   \n",
    "        \n",
    "        #W matriz de pesos. 3D, primera dimensión capa, Segunda dimensión neurona, tercera dimensión pesos. \n",
    "        #Entonces, W[0][0] contendría el arreglo con los pesos de la neurona 0 de la capa 0.\n",
    "        W = []  \n",
    "        for i in range(len(dimensions)): \n",
    "            W.append([])\n",
    "        \n",
    "        #b es un arreglo 2D que contiene el bias de cada neurona b[0][0] contiene el bias de la neurona 0 \n",
    "        #de la capa 0\n",
    "        b = []\n",
    "        for i in range(len(dimensions)): \n",
    "            b.append([])\n",
    "        \n",
    "        \n",
    "        #todas las neuronas en la primera capa deben tener input_lenght pesos. De ahí en adelante, \n",
    "        #cada neurona en la capa j tendrá len(W[j-1]) pesos.\n",
    "        layer_width = dimensions[0]\n",
    "        \n",
    "        for i in range(layer_width):\n",
    "            W[0].append([])\n",
    "            W[0][i] = [random.uniform(-1,1) for j in range(input_length)]\n",
    "            b[0].append(0)\n",
    "            b[0][i] = random.uniform(-1,1)\n",
    "            W[0][i] = np.array([W[0][i]])\n",
    "\n",
    "            \n",
    "        #Inicialización aleatoria de pesos y bias entre -1 y 1\n",
    "        for i in range(1, len(dimensions)):\n",
    "            layer_width = dimensions[i]\n",
    "            for j in range(layer_width):\n",
    "                #se inicializan n valores aleatorios entre -1 y 1 donde n = len(W[i-1])\n",
    "                W[i].append([])\n",
    "                W[i][j] = [random.uniform(-1,1) for j in range(len(W[i-1]))]\n",
    "                b[i].append(0)\n",
    "                #se crea un bias aleatorio para la neurona\n",
    "                b[i][j] = random.uniform(-1,1) \n",
    "            \n",
    "            W[i][j] = np.array([W[i][j]])\n",
    "            \n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        if not self.suppress_output:\n",
    "            print(\"Network Built\")\n",
    "            print(\"W\")\n",
    "            print(W)\n",
    "            print(\"b\")\n",
    "            print(b)\n",
    "            print(\"--------------------------------------------------------------------\")\n",
    "            \n",
    "    #X es una entrada\n",
    "    #W matriz de pesos. 3D, primera dimensión capa, Segunda dimensión neurona, tercera dimensión pesos. \n",
    "    #Entonces, W[0][0] contendría el arreglo con los pesos de la neurona 0 de la capa 0.\n",
    "    #l será el número de capas.\n",
    "    #b es un arreglo 2D que contiene el bias de cada neurona b[0][0] contiene el bias de la neurona 0 \n",
    "    #de la capa 0.\n",
    "    #Algoritmo se basa en el algoritmo 6.3 de GoodFellow et al \n",
    "    #y en el algoritmo de la página 217 de Grus en Data Science from Scratch\n",
    "    def feed_forward(self, x):\n",
    "        \n",
    "        l = len(self.hidden_layer)\n",
    "        \n",
    "        #Salidas de cada neurona. Primera dimensión capa, segunda neuronas\n",
    "        #outputs[0][0] representa la entrada 0 de X. \n",
    "        #outputs[1][0] representa la salida 0 de la primera capa escondida.\n",
    "        \n",
    "        outputs = [np.array([x])]\n",
    "        \n",
    "        for layer in range(l):\n",
    "            \n",
    "            layer_out = []\n",
    "            for neuron in range(len(self.W[layer])):\n",
    "                #a es el resultado de las salidas de la capa anterior por los pesos de la capa actual.\n",
    "                \n",
    "                X = outputs[layer-1].transpose()\n",
    "                W = self.W[layer][neuron]\n",
    "                                \n",
    "                a = np.dot(W,X) + self.b[layer][neuron]\n",
    "                layer_out.append(self.relu(a))\n",
    "                \n",
    "            outputs.append(layer_out)\n",
    "        \n",
    "        if not self.suppess_output:\n",
    "            print(\"Feed_forward outputs\")\n",
    "            print(outputs)\n",
    "            print(\"--------------------------------------------------------------------\")\n",
    "        \n",
    "    def relu(self, z):\n",
    "        print(z)\n",
    "        return max(0,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas de la matriz: 8330\n",
      "Columnas de la matriz: 31\n",
      "[[-18.996       89.147        1.         ... 233.20616681 261.85070337\n",
      "  240.83417734]\n",
      " [-19.347      125.825        4.         ... 227.2751235  261.64357048\n",
      "  332.35653566]\n",
      " [ -9.472      121.707        4.         ... 549.49321044 481.14904868\n",
      "  442.66313626]\n",
      " ...\n",
      " [ -9.494       88.976        4.         ... 519.52773394 538.89585608\n",
      "  313.77593362]\n",
      " [ -7.617       67.929        3.         ... 591.85304812 598.05409088\n",
      "  443.89380682]\n",
      " [-11.774       85.176        3.         ... 659.32142175 531.85019809\n",
      "  607.21596134]]\n",
      "[ 1  1  1 ... -1 -1 -1]\n",
      "X shape(8330, 30)\n",
      "y shape(8330,)\n"
     ]
    }
   ],
   "source": [
    "data_matrix = np.loadtxt(open(\"./msd_genre_dataset/fixed_ds.csv\", \"r\"), delimiter=\",\", skiprows=0)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Filas de la matriz: \" + str(len(data_matrix)))\n",
    "print(\"Columnas de la matriz: \" + str(len(data_matrix[0])))\n",
    "\n",
    "y = data_matrix[:,len(data_matrix[0])-1]\n",
    "X = np.delete(data_matrix, len(data_matrix[0])-1,1)\n",
    "\n",
    "y = y.astype(int)\n",
    "\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "\n",
    "#Se intenta estandarizar X para lograr mejor desempeño. Sin embargo, no parece funcionar.\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "#Los datos del set de datos están agrupados por género. Es decir, primero están todas las filas que corresponden\n",
    "#a 1 y después todas las que corresponden a -1. Se hace un shuffle para que, más tarde, en cross-validation\n",
    "#no se creen unos modelos que predigan únicamente una clase.\n",
    "np.random.shuffle(data_matrix)\n",
    "\n",
    "\n",
    "print(\"X shape\" + str(X.shape))\n",
    "print(\"y shape\" + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Built\n",
      "W\n",
      "[[array([[-2.37369567e-01, -4.15810892e-02, -6.93073585e-01,\n",
      "        -5.14304248e-01, -6.23773354e-01,  8.15989266e-01,\n",
      "        -5.08457788e-01,  7.59591176e-04,  8.56713552e-01,\n",
      "         3.31687514e-01,  1.55571616e-01, -2.15958585e-01,\n",
      "        -8.27033131e-01,  7.99607475e-02, -9.61417110e-02,\n",
      "        -6.09225126e-01, -3.42702716e-01,  6.74090656e-01,\n",
      "        -9.13322957e-01,  5.57186540e-01, -7.93246573e-01,\n",
      "         5.64389545e-01, -7.61018384e-01, -5.18691070e-01,\n",
      "        -1.01908874e-01, -8.26602131e-01, -4.57603250e-01,\n",
      "         3.86067497e-01, -6.37423262e-01, -3.10068938e-01]]), array([[-0.72307096,  0.76487057,  0.57050706, -0.20196446,  0.62180305,\n",
      "        -0.35864486, -0.77694356,  0.91634934, -0.24043276,  0.73079913,\n",
      "        -0.71036276, -0.47330299,  0.53336903,  0.26910665, -0.99471642,\n",
      "         0.62552732,  0.41658873, -0.93029765, -0.81528872,  0.18916015,\n",
      "         0.68162259,  0.58281695,  0.31333196, -0.96239118, -0.45458486,\n",
      "         0.23209881, -0.15602686, -0.22358154, -0.82196387, -0.44290841]]), array([[-0.44644927,  0.90153117,  0.47461638, -0.70321364,  0.34821627,\n",
      "        -0.75761464, -0.57263912, -0.05506268,  0.68646027,  0.72783334,\n",
      "         0.33390769,  0.55412361, -0.41083084, -0.1128327 , -0.33754384,\n",
      "         0.90349514,  0.32086085,  0.64412939, -0.00263702, -0.67313573,\n",
      "        -0.96953985, -0.38376663,  0.47229454, -0.15241101, -0.78210355,\n",
      "         0.25233685, -0.30187358, -0.81394229, -0.29781489,  0.37359973]])], [[0.8067844986568056, -0.9073162805033943, -0.9264792689487193], [0.7570346438777731, -0.6941159100812979, 0.17963917890048964], array([[-0.5548948 , -0.98031645, -0.74047902]])], [[0.7317948717337222, 0.8569140647365743, 0.07173022067878243], [-0.4457232897196064, 0.09083473731899683, -0.9932576072096819], array([[-0.02854643, -0.10635282,  0.12874773]])]]\n",
      "b\n",
      "[[0.4001004851750527, 0.7137416406364254, 0.8056311503274773], [-0.9913058107307329, -0.8797655147684769, -0.4248300677665515], [-0.25408164058306903, 0.7915347567662852, 0.5794949602430877]]\n",
      "--------------------------------------------------------------------\n",
      "[[-1.54730347]]\n",
      "[[0.07138626]]\n",
      "[[1.47799029]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3,) and (30,1) not aligned: 3 (dim 0) != 30 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-2b517ff6fb50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiLayerPerceptronClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppress_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-192-5b06cc92c20d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-192-5b06cc92c20d>\u001b[0m in \u001b[0;36mfeed_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0mlayer_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,) and (30,1) not aligned: 3 (dim 0) != 30 (dim 0)"
     ]
    }
   ],
   "source": [
    "mlp = MultiLayerPerceptronClassifier(hidden_layer = [3, 3, 3], suppress_output = False)\n",
    "\n",
    "mlp.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 12, 16])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
